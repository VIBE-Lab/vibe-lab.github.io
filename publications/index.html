<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Vision Intelligence and Biomedical Exploration Lab - Publications</title>
  <meta name="description" content="Vision Intelligence and Biomedical Exploration Lab -- Publications.">
  <link rel="stylesheet" href="https://vibe-lab.github.io/css/main.css">
  <link rel="canonical" href="https://vibe-lab.github.io/publications/">
<link rel="shortcut icon" type ="image/x-icon" href="https://vibe-lab.github.io/images/logopic/favicon.ico">
<link rel="shortcut icon" href="https://vibe-lab.github.io/favicon.png">


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-26505344-1', 'auto');
  ga('send', 'pageview');

</script>


</head>


  <body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container-fluid">
	<div class="navbar-header">
	  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
		<span class="sr-only">Toggle navigation</span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
	  </button>


    <a class="navbar-brand" href="https://vibe-lab.github.io/">
    	<img style="position:relative; top:-25px" src="/images/logopic/group_logo_medium.png" height="40" width="auto" class="d-inline-block align-left" alt="">
    <a class="navbar-brand" href="https://vibe-lab.github.io/">
			  Vision Intelligence and Biomedical Exploration Lab
    </a>
  	</a>
	</div>
	<div class="collapse navbar-collapse" id="navbar-collapse-1">
	  <ul class="nav navbar-nav navbar-right">
		<li><a href="https://vibe-lab.github.io/">Home</a></li>
		<li><a href="https://vibe-lab.github.io/team">Team</a></li>
		<!--- <li><a href="https://vibe-lab.github.io/openings">Openings</a></li> --->
		<li><a href="https://vibe-lab.github.io/publications">Publications</a></li>
    <!--- <li><a href="https://vibe-lab.github.io/research">Research</a></li> --->
		<!--- <li><a href="https://vibe-lab.github.io/funding">Funding</a></li> --->
		<!--- <li><a href="https://vibe-lab.github.io/pictures">(Pics)</a></li> --->
	  </ul>
	</div>
  </div>
</div>


    <div class="container-fluid">
      <div class="row">
        <div id="gridid" class="col-sm-12">
  <!-- _pages/publications.md -->

<h1 id="publications">Publications</h1>

<p>(See also the personal webpage of our group members)</p>

<h2 id="group-highlights">Group Highlights</h2>

<p>(For a full list of publications, see <a href="#list-of-publications">below</a>, and see also the personal webpage of our group members)</p>

<div class="row">

  <div class="col-sm-12 clearfix">
    <div class="well">
      <pubtit>Cross-Organ and Cross-Scanner Adenocarcinoma Segmentation (COSAS 2024) challenge</pubtit>
      <p><img src="https://vibe-lab.github.io/images/pubpic/cosas.png" class="img-responsive" width="40%" style="float: left" /></p>
      <p>The field of digital pathology has made significant strides in tumor diagnosis and segmentation, driven by various challenges. Despite these advancements, the efficacy of current algorithms encounters a significant challenge due to the inherent diversity present in digital pathology images and tissues. The variances arise from diverse organs, tissue preparation methods, and image acquisition processes, resulting in what is termed as domain-shift. The primary goal of COSAS is to develop strategies that enhance the resilience of computer-aided semantic segmentation solutions against domain-shift, ensuring consistent performance across different organs and scanners. This challenge seeks to advance the development of artificial intelligence and machine learning algorithms for routine diagnostic use in laboratories. Notably, COSAS marks the first challenge in computational histopathology, providing a platform for evaluating domain adaptation methods on a comprehensive dataset featuring diverse organs and scanners from various manufacturers. If the dataset from the challenge is helpful to you, please consider citing <strong><a href="https://dl.acm.org/doi/10.1145/3691521.3691537">our pre-experimental paper</a></strong>. We are currently in the process of finalizing the competition paper and will be releasing it shortly. Thank you for your support!</p>
      <p><em></em></p>
      <div style="text-align: right;">
        <p><strong><a href="https://cosas.grand-challenge.org">Cosas Challenge</a></strong>   <strong><a href="https://drive.google.com/drive/folders/1-F2XLnJ3lUr-sbiKW7qMpsF_ecrfQf4b?usp=sharing">Dataset Download</a></strong></p>

      </div>
      <p class="text-danger"><strong> </strong></p>
      <p> </p>
    </div>
  </div>

</div>

<p>   </p>

<h2 id="list-of-publications">List of Publications</h2>

<h3 id="under-review">Under Review</h3>
<div class="publications">

  <ol class="bibliography"></ol>

</div>

<h3 id="published">Published</h3>
<div class="publications">
  <h3 class="year">2023</h3>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->



      <div class="row">
<!--        <div class="col-sm-2 abbr"></div>
-->
        <!-- Entry bib key -->
        <div id="10222270" class="col-sm-12" display="block">
        <span id="10222270"><b><span style="font-style: bold">“Domain Adaptation of Digital Pathology Images using Joint Stain Color and Image Quality Constraints”</span></b>. <br />
        X. Long, J. Liu, and X. Hou. <br />
        <i>2023 IEEE International Conference on Image Processing (ICIP)</i>, 2023, pp. 1805–1809</span>
    
          <br />
          

          

           
            <a data-toggle="collapse" href="#10222270-abstract" class="btn-abstract" role="button">ABS</a>
          

          <a href="http://dx.doi.org/10.1109/ICIP49359.2023.10222270" target="_blank"><button class="btn-doi">DOI</button></a> 

          

          
          


           
            <a data-toggle="collapse" href="#10222270-bib" class="btn-bib" role="button">BIB</a>
          


          

          
          <div class="collapse" id="10222270-abstract">
            <div class="well-abstract">
            Digital pathology diagnosis systems face significant domain shift problems that hinder their performance on new datasets. Existing methods for aligning digital pathology images from different domains mainly focus on stain color and overlook the potential domain shifts caused by variations in image quality. To address this issue, we propose a novel parametric model that incorporates both stain color and image quality constraints for domain adaptation of digital pathology images. We evaluate our approach on the domain adaptive mitosis detection task through extensive experiments and ablation studies, showing that our method outperforms other state-of-the-art methods.
            </div>
          </div>
          

           
          <div class="collapse" id="10222270-bib">
            <div class="well-bib">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10222270</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Long, Xi and Liu, Jingxin and Hou, Xianxu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 IEEE International Conference on Image Processing (ICIP)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Domain Adaptation of Digital Pathology Images using Joint Stain Color and Image Quality Constraints}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1805-1809}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Image quality;Pathology;Image color analysis;Parametric statistics;Reliability;Clinical diagnosis;Task analysis;digital pathology;domain adaptation;stain color;image quality;mitosis detection}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICIP49359.2023.10222270}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span>
<span class="p">}</span></code></pre></figure>
          </div>
          </div>
          

       

          


        </div>

      </div></li>
<li><!-- _layouts/bib.html -->



      <div class="row">
<!--        <div class="col-sm-2 abbr"></div>
-->
        <!-- Entry bib key -->
        <div id="AUBREVILLE2023102699" class="col-sm-12" display="block">
        <span id="AUBREVILLE2023102699"><b><span style="font-style: bold">“Mitosis domain generalization in histopathology images — The MIDOG challenge”</span></b>. <br />
        M. Aubreville <i>et al.</i> <br />
        <i>Medical Image Analysis</i>, vol. 84, p. 102699, 2023</span>
    
          <br />
          

          <a href="https://www.sciencedirect.com/science/article/pii/S1361841522003279" target="_blank"><button class="btn-pdf">PDF</button></a> 

           
            <a data-toggle="collapse" href="#AUBREVILLE2023102699-abstract" class="btn-abstract" role="button">ABS</a>
          

          <a href="http://dx.doi.org/https://doi.org/10.1016/j.media.2022.102699" target="_blank"><button class="btn-doi">DOI</button></a> 

          

          
          


           
            <a data-toggle="collapse" href="#AUBREVILLE2023102699-bib" class="btn-bib" role="button">BIB</a>
          


          

          
          <div class="collapse" id="AUBREVILLE2023102699-abstract">
            <div class="well-abstract">
            The density of mitotic figures (MF) within tumor tissue is known to be highly correlated with tumor proliferation and thus is an important marker in tumor grading. Recognition of MF by pathologists is subject to a strong inter-rater bias, limiting its prognostic value. State-of-the-art deep learning methods can support experts but have been observed to strongly deteriorate when applied in a different clinical environment. The variability caused by using different whole slide scanners has been identified as one decisive component in the underlying domain shift. The goal of the MICCAI MIDOG 2021 challenge was the creation of scanner-agnostic MF detection algorithms. The challenge used a training set of 200 cases, split across four scanning systems. As test set, an additional 100 cases split across four scanning systems, including two previously unseen scanners, were provided. In this paper, we evaluate and compare the approaches that were submitted to the challenge and identify methodological factors contributing to better performance. The winning algorithm yielded an F1 score of 0.748 (CI95: 0.704-0.781), exceeding the performance of six experts on the same task.
            </div>
          </div>
          

           
          <div class="collapse" id="AUBREVILLE2023102699-bib">
            <div class="well-bib">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">AUBREVILLE2023102699</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mitosis domain generalization in histopathology images — The MIDOG challenge}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Image Analysis}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{84}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{102699}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1361-8415}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.media.2022.102699}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S1361841522003279}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Aubreville, Marc and Stathonikos, Nikolas and Bertram, Christof A. and Klopfleisch, Robert and {ter Hoeve}, Natalie and Ciompi, Francesco and Wilm, Frauke and Marzahl, Christian and Donovan, Taryn A. and Maier, Andreas and Breen, Jack and Ravikumar, Nishant and Chung, Youjin and Park, Jinah and Nateghi, Ramin and Pourakpour, Fattaneh and Fick, Rutger H.J. and {Ben Hadj}, Saima and Jahanifar, Mostafa and Shephard, Adam and Dexl, Jakob and Wittenberg, Thomas and Kondo, Satoshi and Lafarge, Maxime W. and Koelzer, Viktor H. and Liang, Jingtang and Wang, Yubo and Long, Xi and Liu, Jingxin and Razavi, Salar and Khademi, April and Yang, Sen and Wang, Xiyue and Erber, Ramona and Klang, Andrea and Lipnik, Karoline and Bolfa, Pompei and Dark, Michael J. and Wasinger, Gabriel and Veta, Mitko and Breininger, Katharina}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Domain generalization, Histopathology, Challenge, Deep Learning, Mitosis}</span>
<span class="p">}</span></code></pre></figure>
          </div>
          </div>
          

       

          


        </div>

      </div></li></ol>

</div>

</div>

      </div>
    </div>

    <div id="footer" class="panel">
  <div class="panel-footer">
	<div class="container-fluid">
	  <div class="row">
		<div class="col-sm-4">

		  <p>&copy 2024  Vision Intelligence and Biomedical Exploration Lab. Site made with <a href="https://jekyllrb.com">Jekyll</a>;  <a href="https://vibe-lab.github.io/aboutwebsite.html">copy and  modify it for your own research group.</a></p>
              <p>We are part of the <a href="https://www.xjtlu.edu.cn/en/study/departments/school-of-ai-and-advanced-computing">School of AI and Advanced Computing</a> at <a href="https://www.xjtlu.edu.cn/en">Xi’an Jiaotong-Liverpool University</a>.</p>


		   <p>  </p><p>


		</div>
		<!--- <div class="col-sm-4">
		  Funding for early career support:<br />
		  - <a href="https://kaw.wallenberg.org/en/andre-teixeira">Wallenberg Academy Fellow 2023</a> <br />
      - <a href='https://strategiska.se/en/research/ongoing-research/framtidens-forskningsledare-7/'>SSF Future Research Leaders 7</a> <br />
      - <a href="https://www.vr.se/english/applying-for-funding/calls/2018-03-07-starting-grant-within-natural-and-engineering-sciences.html">VR Starting Grant</a> <br />
 			- <a href="http://www.it.uu.se/research/cybersecurity">UU Joint Strategic Research Activities on Cybersecurity</a>, an initiative from the Department of Information Technology <br />
		</div> --->
		<div class="col-sm-4">
		  Contact:<br/>
		  5th Floor, Building D, No.111 Road, Taicang Avenue<br/>
		  Taicang City, Suzhou City<br/>
		  Jiangsu Province<br/>
		  the People’s Republic of China, 215400<br/>
      (<a href="https://map.baidu.com/search/%E8%A5%BF%E4%BA%A4%E5%88%A9%E7%89%A9%E6%B5%A6%E5%A4%A7%E5%AD%A6(%E5%A4%AA%E4%BB%93%E6%A0%A1%E5%8C%BA)/@13488379.727702837,3673585.7257828,18.16z?querytype=s&da_src=shareurl&wd=%E8%A5%BF%E4%BA%A4%E5%88%A9%E7%89%A9%E6%B5%A6%E5%A4%A7%E5%AD%A6(%E5%A4%AA%E4%BB%93%E6%A0%A1%E5%8C%BA)&c=224&src=0&wd2=%E8%8B%8F%E5%B7%9E%E5%B8%82%E5%A4%AA%E4%BB%93%E5%B8%82&pn=0&sug=1&l=12&b=(13362680.33,3620809.01;13485560.33,3679113.01)&from=webmap&biz_forward=%7B%22scaler%22:1,%22styles%22:%22pl%22%7D&sug_forward=baddcc906d1715654007c1df&device_ratio=1">Maps</a>, <a href="https://www.xjtlu.edu.cn/en/study/departments/school-of-ai-and-advanced-computing/contact">Contacts and Directions</a>)
		</div>
	  </div>
	</div>
  </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="https://vibe-lab.github.io/js/bootstrap.min.js"></script>


  </body>

</html>
